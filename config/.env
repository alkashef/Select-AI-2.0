# Prompt template
PROMPT_PATH=./prompt.txt # Options: prompt_teradata.txt, prompt_postgres.txt

# TD connection
TD_HOST='raven-env-oe7lr1dbadydeuff.env.clearscape.teradata.com'
TD_NAME='raven'
TD_USER='demo_user'
TD_PASSWORD='raven$1234'
TD_PORT='1025'

# Model Configuration (for the huggingface engine only)
MODEL_PATH="./models/code-llama-7b-instruct"
MAX_LENGTH=4096 # Maximum context window size for the model
TOKEN_GENERATION_LIMIT=192 # Controls how many new tokens the model will generate during inference
INPUT_CONTEXT_LENGTH=768 # Controls how much of the input prompt is tokenized and fed to the model
RESULT_LIMIT=1
HF_HUB_OFFLINE=1

# Logging Configuration
LOG_FILE_PATH=.\logs\log.txt 
